##### 1、进程与线程

1）基本概念：

​    进程是对运行时程序的封装，是系统进行资源调度和分配的的基本单位，实现了操作系统的并发；

​    线程是进程的子任务，是CPU调度和分派的基本单位，用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的最小执行和调度单位。每个线程都独自占用一个虚拟处理器：独自的寄存器组，指令计数器和处理器状态。每个线程完成不同的任务，但是共享同一地址空间（也就是同样的动态内存，映射文件，目标代码等等），打开的文件队列和其他内核资源。

##### **2、进程和线程的区别：**

1）一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。线程依赖于进程而存在。

2）进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。）

3）进程是资源分配的最小单位，线程是CPU调度的最小单位；

4）系统开销：由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／o设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，进程切换的开销也远大于线程切换的开销。

5）通信：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预

6）进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂。

7）进程间不会相互影响 ；线程一个线程挂掉将导致整个进程挂掉

8）进程适应于多核、多机分布；线程适用于多核

**3、进程间通信的方式**

​    进程间通信主要包括管道、系统IPC（包括消息队列、信号量、信号、共享内存等）、以及套接字socket。

1）管道：

​    管道主要包括无名管道和命名管道:管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信

匿名管道PIPE：

​    它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端

​    它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）

​    它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

命名管道FIFO：

​    FIFO可以在无关的进程之间交换数据

​    FIFO有路径名与之相关联，它以一种特殊设备文件形式存在于文件系统中。

2）消息队列

​    消息队列，是消息的链接表，存放在内核中。一个消息队列由一个标识符（即队列ID）来标记。(消息队列克服了信号传递信息少，管道只能承载无格式字节流以及缓冲区大小受限等特点)具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息；

特点：

​    消息队列是面向记录的，其中的消息具有特定的格式以及特定的优先级。

​    消息队列独立于发送与接收进程。进程终止时，消息队列及其内容并不会被删除。

​    消息队列可以实现消息的随机查询，消息不一定要以先进先出的次序读取，也可以按消息的类型读取。

3）信号量semaphore

​    信号量（semaphore）与已经介绍过的IPC结构不同，它是一个计数器，可以用来控制多个进程对共享资源的访问。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

特点：

​    信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。

​    信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。

​    每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。

​    支持信号量组。

4）信号signal

​    信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

5）共享内存（Shared Memory）

​    它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等

特点：

​    共享内存是最快的一种IPC，因为进程是直接对内存进行存取

​    因为多个进程可以同时操作，所以需要进行同步

​    信号量+共享内存通常结合在一起使用，信号量用来同步对共享内存的访问

6）套接字SOCKET：

​    socket也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同主机之间的进程通信。

**4、线程间通信的方式**

1）临界区：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；

2）互斥量Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问

3）信号量Semphare：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。

4）事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作 

**5、Linux虚拟地址空间**

​    为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。

​    虚拟内存技术使得不同进程在运行过程中，它所看到的是自己独自占有了当前系统的4G内存。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。 事实上，在每个进程创建加载时，内核只是为进程“创建”了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如.text .data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据。还有进程运行过程中，要动态分配内存，比如malloc时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。

​    请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。

**虚拟内存的好处**：

1）扩大地址空间；

2）内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。

3）公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。

4）当进程通信时，可采用虚存共享的方式实现。

5）当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存

6）虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高

7）在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片

**虚拟内存的代价：**

1）虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存

2）虚拟地址到物理地址的转换，增加了指令的执行时间。

3）页面的换入换出需要磁盘I/O，这是很耗时的

4）如果一页中只有一部分数据，会浪费内存。

**6、操作系统的缺页中断**

​    malloc()和mmap()等内存分配函数，在分配时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。当进程访问这些没有建立映射关系的虚拟内存时，处理器自动触发一个缺页异常。

​    缺页中断：在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存是，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：

1）保护CPU现场

2）分析中断原因

3）转入缺页中断处理程序进行处理

4）恢复CPU现场，继续执行

​    但是缺页中断是由于所要访问的页面不存在于内存时，由硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：

1）在指令执行期间产生和处理缺页中断信号

2）一条指令在执行期间，可能产生多次缺页中断

3）缺页中断返回是，执行产生中断的一条指令，而一般的中断返回是，执行下一条指令。

**7、并发和并行**

​    并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，你的指令之间穿插着我的指令，我的指令之间穿插着你的，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率。

​    并行（parallelism）：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展。

**8、操作系统页表寻址**

​    页式内存管理，内存分成固定长度的一个个页片。操作系统为每一个进程维护了一个从虚拟地址到物理地址的映射关系的数据结构，叫页表，页表的内容就是该进程的虚拟地址到物理地址的一个映射。页表中的每一项都记录了这个页的基地址。通过页表，由逻辑地址的高位部分先找到逻辑地址对应的页基地址，再由页基地址偏移一定长度就得到最后的物理地址，偏移的长度由逻辑地址的低位部分决定。一般情况下，这个过程都可以由硬件完成，所以效率还是比较高的。页式内存管理的优点就是比较灵活，内存管理以较小的页为单位，方便内存换入换出和扩充地址空间。

**9、单核机器上写多线程程序，是否需要考虑加锁，为什么？**

​    在单核机器上写多线程程序，仍然需要线程锁。因为线程锁通常用来实现线程的同步和通信。在单核机器上的多线程程序，仍然存在线程同步的问题。因为在抢占式操作系统中，通常为每个线程分配一个时间片，当某个线程时间片耗尽时，操作系统会将其挂起，然后运行另一个线程。如果这两个线程共享某些数据，不使用线程锁的前提下，可能会导致共享数据修改引起冲突。

 

**10、请问线程需要保存哪些上下文，SP、PC、EAX这些寄存器是干嘛用的**

​    线程在切换的过程中需要保存当前线程Id、线程状态、堆栈、寄存器状态等信息。其中寄存器主要包括SP PC EAX等寄存器，其主要功能如下：

SP:堆栈指针，指向当前栈的栈顶地址

PC:程序计数器，存储下一条将要执行的指令

EAX:累加寄存器，用于加法乘法的缺省寄存器

**11、操作系统缺页置换算法**

​    当访问一个内存中不存在的页，并且内存已满，则需要从内存中调出一个页或将数据送至磁盘对换区，替换一个页，这种现象叫做缺页置换。当前操作系统最常采用的缺页置换算法如下：

1）先进先出(FIFO)算法：置换最先调入内存的页面，即置换在内存中驻留时间最久的页面。按照进入内存的先后次序排列成队列，从队尾进入，从队首删除。

2）最近最少使用（LRU）算法: 置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。

当前最常采用的就是LRU算法。

**12、死锁发生条件以及如何解决**

死锁是指两个或两个以上进程在执行过程中，因争夺资源而造成的下相互等待的现象。死锁发生的四个必要条件如下：

互斥条件：进程对所分配到的资源不允许其他进程访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源；

请求和保持条件：进程获得一定的资源后，又对其他资源发出请求，但是该资源可能被其他进程占有，此时请求阻塞，但该进程不会释放自己已经占有的资源；

不可剥夺条件：进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用后自己释放；

环路等待条件：进程发生死锁后，必然存在一个进程-资源之间的环形链；

解决死锁的方法即破坏上述四个条件之一，主要方法如下：

资源一次性分配，从而剥夺请求和保持条件；

可剥夺资源：即当进程新的资源未得到满足时，释放已占有的资源，从而破坏不可剥夺的条件；

资源有序分配法：系统给每类资源赋予一个序号，每个进程按编号递增的请求资源，释放则相反，从而破坏环路等待的条件；

**13、操作系统中的结构体对齐，字节对齐**

1）原因：

​    平台原因（移植原因）：不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。

​    性能原因：数据结构（尤其是栈）应该尽可能地在自然边界上对齐。原因在于，为了访问未对齐的内存，处理器需要作两次内存访问；而对齐的内存访问仅需要一次访问。

2）规则

​    数据成员对齐规则：结构(struct)(或联合(union))的数据成员，第一个数据成员放在offset为0的地方，以后每个数据成员的对齐按照#pragma pack指定的数值和这个数据成员自身长度中，比较小的那个进行。

​    结构(或联合)的整体对齐规则：在数据成员完成各自对齐之后，结构(或联合)本身也要进行对齐，对齐将按照#pragma pack指定的数值和结构(或联合)最大数据成员长度中，比较小的那个进行。

​    结构体作为成员：如果一个结构里有某些结构体成员，则结构体成员要从其内部最大元素大小的整数倍地址开始存储。

3）定义结构体对齐

可以通过预编译命令#pragma pack(n)，n=1,2,4,8,16来改变这一系数，其中的n就是指定的“对齐系数”。

4）举例

\#pragma pack(2)

struct AA {

int a;    //长度4 > 2 按2对齐；偏移量为0；存放位置区间[0,3]

char b;  //长度1 < 2 按1对齐；偏移量为4；存放位置区间[4]

short c;   //长度2 = 2 按2对齐；偏移量要提升到2的倍数6；存放位置区间[6,7]

char d;  //长度1 < 2 按1对齐；偏移量为7；存放位置区间[8]；共12个字节

};

\#pragma pack()

**14、请你讲述一下互斥锁（mutex）机制，以及互斥锁和读写锁的区别**

1）互斥锁和读写锁区别：

互斥锁：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒。

读写锁：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。

互斥锁和读写锁的区别：

​    1）读写锁区分读者和写者，而互斥锁不区分

​    2）互斥锁同一时间只允许一个线程访问该对象，无论读写；读写锁同一时间内只允许一个写者，但是允许多个读者同时读对象。

2）Linux的4种锁机制：

**互斥锁**：mutex，用于保证在任何时刻，都只能有一个线程访问该对象。当获取锁操作失败时，线程会进入睡眠，等待锁释放时被唤醒

**读写锁**：rwlock，分为读锁和写锁。处于读操作时，可以允许多个线程同时获得读操作。但是同一时刻只能有一个线程可以获得写锁。其它获取写锁失败的线程都会进入睡眠状态，直到写锁释放时被唤醒。 注意：写锁会阻塞其它读写锁。当有一个线程获得写锁在写时，读锁也不能被其它线程获取；写者优先于读者（一旦有写者，则后续读者必须等待，唤醒时优先考虑写者）。适用于读取数据的频率远远大于写数据的频率的场合。

**自旋锁**：spinlock，在任何时刻同样只能有一个线程访问对象。但是当获取锁操作失败时，不会进入睡眠，而是会在原地自旋，直到锁被释放。这样节省了线程从睡眠状态到被唤醒期间的消耗，在加锁时间短暂的环境下会极大的提高效率。但如果加锁时间过长，则会非常浪费CPU资源。

**RCU**：即read-copy-update，在修改数据时，首先需要读取数据，然后生成一个副本，对副本进行修改。修改完成后，再将老数据update成新的数据。使用RCU时，读者几乎不需要同步开销，既不需要获得锁，也不使用原子指令，不会导致锁竞争，因此就不用考虑死锁问题了。而对于写者的同步开销较大，它需要复制被修改的数据，还必须使用锁机制同步并行其它写者的修改操作。在有大量读操作，少量写操作的情况下效率非常高。

**15、进程状态转换图，动态就绪，静态就绪，动态阻塞，静态阻塞**                         

1）创建状态：进程正在被创建

2）就绪状态：进程被加入到就绪队列中等待CPU调度运行

3）执行状态：进程正在被运行

4）等待阻塞状态：进程因为某种原因，比如等待I/O，等待设备，而暂时不能运行。

5）终止状态：进程运行完毕

​    当多个进程竞争内存资源时，会造成内存资源紧张，并且，如果此时没有就绪进程，处理机会空闲，I/0速度比处理机速度慢得多，可能出现全部进程阻塞等待I/O。

​    针对以上问题，提出了两种解决方法：

​    1）交换技术：换出一部分进程到外存，腾出内存空间。

​    2）虚拟存储技术：每个进程只能装入一部分程序和数据。

​    在交换技术上，将内存暂时不能运行的进程，或者暂时不用的数据和程序，换出到外存，来腾出足够的内存空间，把已经具备运行条件的进程，或进程所需的数据和程序换入到内存。

​    从而出现了进程的挂起状态：进程被交换到外存，进程状态就成为了挂起状态。

**活动阻塞，静止阻塞，活动就绪，静止就绪**

1）活动阻塞：进程在内存，但是由于某种原因被阻塞了。

2）静止阻塞：进程在外存，同时被某种原因阻塞了。

3）活动就绪：进程在内存，处于就绪状态，只要给CPU和调度就可以直接运行。

4）静止就绪：进程在外存，处于就绪状态，只要调度到内存，给CPU和调度就可以运行。

从而出现了：

活动就绪 ——  静止就绪    （内存不够，调到外存）

活动阻塞 ——  静止阻塞    （内存不够，调到外存）

执行   ——  静止就绪     （时间片用完）

##### 16、A\* a = new A; a->i = 10;在内核中的内存分配上发生了什么？

1）A *a：a是一个局部变量，类型为指针，故而操作系统在程序栈区开辟4/8字节的空间（0x000m），分配给指针a。

2）new A：通过new动态的在堆区申请类A大小的空间（0x000n）。

3）a = new A：将指针a的内存区域填入栈中类A申请到的地址的地址。即*（0x000m）=0x000n。

4）a->i：先找到指针a的地址0x000m，通过a的值0x000n和i在类a中偏移offset，得到a->i的地址0x000n + offset，进行*(0x000n + offset) = 10的赋值操作，即内存0x000n + offset的值是10。

**17、软链接和硬链接区别**

​    为了解决文件共享问题，Linux引入了软链接和硬链接。除了为Linux解决文件共享使用，还带来了隐藏文件路径、增加权限安全及节省存储等好处。若1个inode号对应多个文件名，则为硬链接，即硬链接就是同一个文件使用了不同的别名,使用ln创建。若文件用户数据块中存放的内容是另一个文件的路径名指向，则该文件是软连接。软连接是一个普通文件，有自己独立的inode,但是其数据块内容比较特殊。

**18、用户态和内核态的区别**

​    用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同。用户态拥有最低的特权级，内核态拥有较高的特权级。运行在用户态的程序不能直接访问操作系统内核数据结构和程序。内核态和用户态之间的转换方式主要包括：系统调用，异常和中断。

**19、 如何设计server，使得能够接收多个客户端的请求**

多线程、线程池、io复用

**20、死循环+来连接时新建线程的方法效率有点低，怎么改进？**

​    提前创建好一个线程池，用生产者消费者模型，创建一个任务队列，队列作为临界资源，有了新连接，就挂在到任务队列上，队列为空所有线程睡眠。改进死循环：使用select epoll这样的技术。

**21、怎么唤醒被阻塞的socket线程**

给阻塞时候缺少的资源

**22、就绪状态的进程正在等待什么**

被调度使用cpu的运行权

**23、多线程的同步，锁的机制**

​    同步的时候用一个互斥量，在访问共享资源前对互斥量进行加锁，在访问完成后释放互斥量上的锁。对互斥量进行加锁以后，任何其他试图再次对互斥量加锁的线程将会被阻塞直到当前线程释放该互斥锁。如果释放互斥锁时有多个线程阻塞，所有在该互斥锁上的阻塞线程都会变成可运行状态，第一个变为运行状态的线程可以对互斥量加锁，其他线程将会看到互斥锁依然被锁住，只能回去再次等待它重新变为可用。在这种方式下，每次只有一个线程可以向前执行。

**24、两个进程访问临界区资源，会不会出现都获得自旋锁的情况？**

单核cpu，并且开了抢占可以造成这种情况

**25、windows消息机制**

当用户有操作(鼠标，键盘等)时，系统会将这些时间转化为消息。每个打开的进程系统都为其维护了一个消息队列，系统会将这些消息放到进程的消息队列中，而应用程序会循环从消息队列中取出来消息，完成对应的操作。

**26、内存溢出和内存泄漏**

1）内存溢出

​    指程序申请内存时，没有足够的内存供申请者使用。内存溢出就是你要的内存空间超过了系统实际分配给你的空间，此时系统相当于没法满足你的需求，就会报内存溢出的错误

内存溢出原因：

​    内存中加载的数据量过于庞大，如一次从数据库取出过多数据

​    集合类中有对对象的引用，使用完后未清空，使得不能回收

​    代码中存在死循环或循环产生过多重复的对象实体

​    使用的第三方软件中的BUG

​    启动参数内存值设定的过小

2）内存泄漏

​    内存泄漏是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。

内存泄漏的分类：

（1）堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc，realloc new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。

（2）系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。

（3）没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。

**27、协程**

1）概念：

协程，又称微线程，纤程，英文名Coroutine。协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。

2）协程和线程区别

那和多线程比，协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。

第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。

3）其他

在协程上利用多核CPU呢——多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。

Python对协程的支持还非常有限，用在generator中的yield可以一定程度上实现协程。虽然支持不完全，但已经可以发挥相当大的威力了。

**28、系统调用**

1）概念：

​    在计算机中，系统调用（英语：system call），又称为系统呼叫，指运行在使用者空间的程序向操作系统内核请求需要更高权限运行的服务。系统调用提供了用户程序与操作系统之间的接口（即系统调用是用户程序和内核交互的接口）。

​    操作系统中的状态分为管态（核心态）和目态（用户态）。大多数系统交互式操作需求在内核态执行。如设备IO操作或者进程间通信。特权指令：一类只能在核心态下运行而不能在用户态下运行的特殊指令。不同的操作系统特权指令会有所差异，但是一般来说主要是和硬件相关的一些指令。用户程序只在用户态下运行，有时需要访问系统核心功能，这时通过系统调用接口使用系统调用。

​    应用程序有时会需要一些危险的、权限很高的指令，如果把这些权限放心地交给用户程序是很危险的(比如一个进程可能修改另一个进程的内存区，导致其不能运行)，但是又不能完全不给这些权限。于是有了系统调用，危险的指令被包装成系统调用，用户程序只能调用而无权自己运行那些危险的指令。另外，计算机硬件的资源是有限的，为了更好的管理这些资源，所有的资源都由操作系统控制，进程只能向操作系统请求这些资源。操作系统是这些资源的唯一入口，这个入口就是系统调用。

2）系统调用举例：

对文件进行写操作，程序向打开的文件写入字符串“hello world”，open和write都是系统调用。

**29、用户态到内核态的转换原理**

1）系统调用

这是用户进程主动要求切换到内核态的一种方式，用户进程通过系统调用申请操作系统提供的服务程序完成工作。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的ine 80h中断。

2）异常

当CPU在执行运行在用户态的程序时，发现了某些事件不可知的异常，这是会触发由当前运行进程切换到处理此。异常的内核相关程序中，也就到了内核态，比如缺页异常。

3）外围设备的中断

当外围设备完成用户请求的操作之后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条将要执行的指令，转而去执行中断信号的处理程序，如果先执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了有用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

**30、动态链接和静态链接**

1）静态链接：

​    函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，链接器从库中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。

​    空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本；

​    更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。

​    运行速度快：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西，在执行的时候运行速度快。

2）动态链接：

​    动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。

​    共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多分，副本，而是这多个程序在执行时共享同一份副本；

​    更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。

​    性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。

**31、微内核和宏内核**

1）宏内核：除了最基本的进程、线程管理、内存管理外，将文件系统，驱动，网络协议等等都集成在内核里面，例如linux内核。

优点：效率高。

缺点：稳定性差，开发过程中的bug经常会导致整个系统挂掉。

2）微内核：内核中只有最基本的调度、内存管理。驱动、文件系统等都是用户态的守护进程去实现的。

优点：稳定，驱动等的错误只会导致相应进程死掉，不会导致整个系统都崩溃

缺点：效率低。典型代表QNX，QNX的文件系统是跑在用户态的进程，称为resmgr的东西，是订阅发布机制，文件系统的错误只会导致这个守护进程挂掉。不过数据吞吐量就比较不乐观了。 

**32、僵尸进程**

1）正常进程

​    正常情况下，子进程是通过父进程创建的，子进程再创建新的进程。子进程的结束和父进程的运行是一个异步过程，即父进程永远无法预测子进程到底什么时候结束。 当一个进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。

​    unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到：在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存等。 但是仍然为其保留一定的信息，直到父进程通过wait / waitpid来取时才释放。保存信息包括：

​    1进程号the process ID

​    2退出状态the termination status of the process

​    3运行时间the amount of CPU time taken by the process等

2）孤儿进程

​    一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。

3）僵尸进程

​    一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。

​    僵尸进程是一个进程必然会经过的过程：这是每个子进程在结束时都要经过的阶段。

​    如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。

如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。

危害：

​    如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程。

外部消灭：

​    通过kill发送SIGTERM或者SIGKILL信号消灭产生僵尸进程的进程，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源

内部解决：

​    1、子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。

​    2、fork两次，原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。

**33、5种IO模型**

​    1）阻塞IO:调用者调用了某个函数，等待这个函数返回，期间什么也不做，不停的去检查这个函数有没有返回，必须等这个函数返回才能进行下一步动作

​    2）非阻塞IO:非阻塞等待，每隔一段时间就去检测IO事件是否就绪。没有就绪就可以做其他事。

​    3）信号驱动IO:信号驱动IO:linux用套接口进行信号驱动IO，安装一个信号处理函数，进程继续运行并不阻塞，当IO时间就绪，进程收到SIGIO信号。然后处理IO事件。

​    4）IO复用/多路转接IO:linux用select/poll函数实现IO复用模型，这两个函数也会使进程阻塞，但是和阻塞IO所不同的是这两个函数可以同时阻塞多个IO操作。而且可以同时对多个读操作、写操作的IO函数进行检测。知道有数据可读或可写时，才真正调用IO操作函数

​    5）异步IO:linux中，可以调用aio_read函数告诉内核描述字缓冲区指针和缓冲区的大小、文件偏移及通知的方式，然后立即返回，当内核将数据拷贝到缓冲区后，再通知应用程序。

**34、异步编程的事件循环**

​    事件循环就是不停循环等待时间的发生，然后将这个事件的所有处理器，以及他们订阅这个事件的时间顺序依次依次执行。当这个事件的所有处理器都被执行完毕之后，事件循环就会开始继续等待下一个事件的触发，不断往复。当同时并发地处理多个请求时，以上的概念也是正确的，可以这样理解：在单个的线程中，事件处理器是一个一个按顺序执行的。即如果某个事件绑定了两个处理器，那么第二个处理器会在第一个处理器执行完毕后，才开始执行。在这个事件的所有处理器都执行完毕之前，事件循环不会去检查是否有新的事件触发。在单个线程中，一切都是有顺序地一个一个地执行的！

**35、为什么要有page cache，操作系统怎么设计的page cache**

​    加快从磁盘读取文件的速率。page cache中有一部分磁盘文件的缓存，因为从磁盘中读取文件比较慢，所以读取文件先去page cache中去查找，如果命中，则不需要去磁盘中读取，大大加快读取速度。在 Linux 内核中，文件的每个数据块最多只能对应一个 Page Cache 项，它通过两个数据结构来管理这些 Cache项，一个是radix tree，另一个是双向链表。Radix tree 是一种搜索树，Linux内核利用这个数据结构来通过文件内偏移快速定位Cache 项。

**36、请问怎么实现线程池**

1）设置一个生产者消费者队列，作为临界资源

2）初始化n个线程，并让其运行起来，加锁去队列取任务运行

3）当任务队列为空的时候，所有线程阻塞

4）当生产者队列来了一个任务后，先对队列加锁，把任务挂在到队列上，然后使用条件变量去通知阻塞中的一个线程

**37、linux内核的Timer定时器机制**

1）低精度时钟

Linux 2.6.16之前，内核只支持低精度时钟，内核定时器的工作方式：

​    1、系统启动后，会读取时钟源设备(RTC, HPET，PIT…)，初始化当前系统时间。

​    2、内核会根据HZ(系统定时器频率，节拍率)参数值，设置时钟事件设备，启动tick(节拍)中断。HZ表示1秒种产生多少个时钟硬件中断，tick就表示连续两个中断的间隔时间。

​    3、设置时钟事件设备后，时钟事件设备会定时产生一个tick中断，触发时钟中断处理函数，更新系统时钟,并检测timer wheel，进行超时事件的处理。

​    在上面工作方式下，Linux 2.6.16 之前，内核软件定时器采用timer wheel多级时间轮的实现机制，维护操作系统的所有定时事件。timer wheel的触发是基于系统tick周期性中断。

所以说这之前，linux只能支持ms级别的时钟，随着时钟源硬件设备的精度提高和软件高精度计时的需求，有了高精度时钟的内核设计。

2）高精度时钟

Linux 2.6.16 ，内核支持了高精度的时钟，内核采用新的定时器hrtimer，其实现逻辑和Linux 2.6.16 之前定时器逻辑区别：

hrtimer采用红黑树进行高精度定时器的管理，而不是时间轮；

高精度时钟定时器不在依赖系统的tick中断，而是基于事件触发。

旧内核的定时器实现依赖于系统定时器硬件定期的tick，基于该tick，内核会扫描timer wheel处理超时事件，会更新jiffies，wall time(墙上时间，现实时间)，process的使用时间等等工作。

新的内核不再会直接支持周期性的tick，新内核定时器框架采用了基于事件触发，而不是以前的周期性触发。新内核实现了hrtimer(high resolution timer)：于事件触发。

hrtimer的工作原理：

​    通过将高精度时钟硬件的下次中断触发时间设置为红黑树中最早到期的Timer 的时间，时钟到期后从红黑树中得到下一个 Timer 的到期时间，并设置硬件，如此循环反复。

​    在高精度时钟模式下，操作系统内核仍然需要周期性的tick中断，以便刷新内核的一些任务。hrtimer是基于事件的，不会周期性出发tick中断，所以为了实现周期性的tick中断(dynamic tick)：系统创建了一个模拟 tick 时钟的特殊 hrtimer，将其超时时间设置为一个tick时长，在超时回来后，完成对应的工作，然后再次设置下一个tick的超时时间，以此达到周期性tick中断的需求。

引入了dynamic tick，是为了能够在使用高精度时钟的同时节约能源，这样会产生tickless 情况下，会跳过一些 tick。

新内核对相关的时间硬件设备进行了统一的封装，定义了主要有下面两个结构：

时钟源设备(closk source device)：抽象那些能够提供计时功能的系统硬件，比如 RTC(Real Time Clock)、TSC(Time Stamp Counter)，HPET，ACPI PM-Timer，PIT等。不同时钟源提供的精度不一样，现在pc大都是支持高精度模式(high-resolution mode)也支持低精度模式(low-resolution mode)。

时钟事件设备(clock event device)：系统中可以触发 one-shot（单次）或者周期性中断的设备都可以作为时钟事件设备。

当前内核同时存在新旧timer wheel 和 hrtimer两套timer的实现，内核启动后会进行从低精度模式到高精度时钟模式的切换，hrtimer模拟的tick中断将驱动传统的低精度定时器系统（基于时间轮）和内核进程调度。

**38、匿名管道和命名管道**

1）匿名管道:管道是半双工的，数据只能单向通信；需要双方通信时，需要建立起两个管道；只能用于父子进程或者兄弟进程之间（具有亲缘关系的进程）。

2）命名管道：可在同一台计算机的不同进程之间或在跨越一个网络的不同计算机的不同进程之间，支持可靠的、单向或双向的[数据通信](https://link.jianshu.com?t=http:/baike.baidu.com/subview/49233/49233.htm)。

**39、多线程的共享资源和独享**

栈是每个线程独有的，线程之间共享的资源有代码段、堆空间、数据段、打开的文件；

**40、线程、进程间的同步**

同步是指并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种互相制约的等待与互通信息称为进程/线程同步。



 

 

## 一、深度理解操作系统第一章

**1、操作系统组成：进程管理、存储管理、文件管理、设备管理、系统调用**

**2、操作系统特征：**

1）并发（计算机系统中同时存在多个运行的程序，需要OS管理和调度）

2）共享（“同时”访问、互斥共享）

3）虚拟（利用多道程序设计技术，让每个用户都觉得有一个计算机为他服务）

4）异步（程序的执行不是一贯到底，而是走走停停，向前推进的速度不可预知；但只要运行环境相同，OS需要保证程序运行的结果也相同）

##### 3、Linux Windows Android的界面属于外壳(Shell)，而不是内核(kernel)。操作系统研究的是内核，处于Shell之下。

**4、异步、同步**

## 二、操作系统基本操作

**1、中断、异常、系统调用**

1）系统调用：(来源于应用程序)应用程序主动向操作系统发出服务请求。

2）异常：(来源于不良的应用程序)非法指令或其它花的处理状态(e.g.内存出错)。

3）中断：(来源于外设)来自不同的硬件设备的计时器和网络的中断。

4）处理时间

​    -中断：异步；

​    -异常：同步；

​    -系统调用：同步或异步。

5）响应

​    -中断：持续，对用户应用程序时透明的

​    -异常：杀死或者重新执行意想不到的应用程序指令

​    -系统调用：等待和持续

**2、中断、异常处理机制**

1）中断是外设的事件，异常是CPU的事件；中断/异常迫使CPU访问一些被中断和异常服务访问的功能。

2）中断处理机制

硬件：设置中断标记(CPU初始化)

​    -将内部/外部事件设置中断标记；

​    -中断事件的ID(程序访问的中断向量地址)

软件(操作系统)：

​    -保存当前处理状态

​    -中断服务程序处理

​    -清除中断标记

​    -恢复之前保存的处理状态

3）异常处理机制

异常：异常编号

​    -保存现场

​    -异常处理：杀死产生异常的程序；重新执行异常指令

​    -恢复现场

4）系统调用

​    -一条指令会触发一个系统调用

​    -程序访问主要是通过高层次的API接口而不是直接进行系统调用。

​    -通常情况下，存在与每个系统调用相关的序号，系统调用接口根据这些序号来维护表的索引。

​    -系统调用接口调用内核态中预期的系统调用，并返回系统调用的状态和其它任何返回值。

​    -用户不需要知道系统调用是如何实现的，只需要获取API和了解操作新系统将什么作为返回结果。操作系统接口的细节大部分都隐藏在API中，并通过运行程序支持的库来管理。

​    -用户态：应用程序在执行的过程中，CPU执行的特权级的状态(很低，不能访问特殊机器指令和IO)。

​    -内核态：应用程序在执行的过程中，CPU执行的特权级的状态(高，操作系统可以执行CPU任何一条指令)。

​    -系统调用时涉及到特权级从用户态到内核态的转换，应用程序和操作系统有各自的堆栈，这两个变化比函数调用的开销更大，但更安全和可靠。(而程序调用是在一个栈空间实现参数的调用和返回)。

5）跨越操作系统边界的开销

​    -在执行时间上超过程序调用

​    -开销包括：

​       建立中断/异常/系统调用号与对应服务例程映射关系的初始化开销；

​       建立内核堆栈(操作系统和应用程序的堆栈不一样)；

​       验证参数(操作系统会检查数据)；

​       内核态映射到用户态的地址空间，更新页面映射权限(内存拷贝开销)；

​       内核态独立地址空间TLB。

## 三、内存管理

**1、计算机体系结构及内存分层体系**

1）CPU

2）内存

3）外设

**2、CPU访问速度由高到低**：CPU寄存器>cache>主存>磁盘>磁带

**3、操作系统在内存管理要完成的目标**

-抽象：逻辑地址空间

-保护：独立地址空间

-共享：访问相同内存

-虚拟化：更多的地址空间

**4、地址空间与地址生成**

1）地址空间的定义：

​    -物理地址空间：硬件支持的地址空间

​    -逻辑地址空间：一个运行的程序所拥有的内存范围

2）地址空间的生成

3）应用程序的逻辑地址如何映射到物理地址？

​    =>CPU方面

​    a.运算器ALU需要在逻辑地址的内存内容(CPU要逻辑地址)

​    b.内存管理单元MMU寻找在逻辑地址和物理地址之间的映射(然后MMU找逻辑和物理地址的关系)

​    c. 控制器从总线发送在物理地址的内存内容的请求(关系找到后，去找对应物理地址)

​    =>内存方面

​    e.内存发送物理地址内存内容给CPU(物理地址找到了，给CPU)

​    =>操作系统方面

​    f.建立逻辑地址和物理地址之间的映射(确保程序不相互干扰)

4）地址安全检查

**5、连续内存分配：内存碎片与分区的动态分配**

1）内存碎片问题

-空闲内存不能被利用

外部碎片：在分配单元间的未使用内存

内部碎片：在分配单元中的未使用内存

2）简单的内存管理方法

-当一个程序准许运行在内存中时，分配一个连续的区间

-分配一个连续的内存区间给运行的程序以访问数据

3）分区的动态分配策略

a、首次适配

​    –内容：现在想分配n字节，从低地址开始找，碰到的第一个空间比n大的空闲块就使用它。

​    –要想实现首次分配，需要满足以下条件：

​       需要存在一个按地址排序的空闲块列表

​       分配需要找一个合适的分区

​       重分配需要检查，看看自由分区能不能与相邻的空闲分区合并(形成更大的空闲块)，若有

​    –优点：简单；易于产生更大的空闲块，向着地址空间的结尾；

​    –缺点：外部碎片的问题会加剧；不确定性；

b、最佳适配

​    –内容：为了分配n字节，使用最小的可用空闲块，以致块的尺寸比n大；

​    –目的：避免分割大的空闲块；最小化外部碎片产生的尺寸。

​    –要想实现最佳分配，需要满足以下条件：

​       按尺寸排列的空闲列表；

​       分配需要寻找一个合适的分区；

​       重分配需要搜索和合并于相邻的空闲分区，若有；

​    –优点：大部分分配是小尺寸时很有效；简单；

​    –缺点：外部碎片；重分配慢；易产生很多没用的微小碎片。

c、最差适配

​    –内容：为了分配n字节，使用最大的可用空闲块，以致块的尺寸比n大。

​    –目的：避免太多的微小碎片

​    –要想实现最差分配，需要满足以下条件：

​       按尺寸排列的空闲列表

​       分配很快(获得最大的分区)

​       重分配需要合并于相邻的空闲分区，若有，然后调整空闲块列表

​    –优点：假如分配时是中等尺寸效果最好；

​    –缺点：重分配慢；外部碎片；易于破碎大的空闲块以至大分区不能被分割；

##### 6、连续内存分配：压缩式与交换式碎片整理

1）压缩式碎片整理（紧致）

​    -重置程序以合并孔洞；

​    -要求所有程序是动态可重置的；

​    -问题：何时重置；开销；

2）交换式碎片整理

​    -运行程序需要更多的内存；

​    -抢占等待的程序或回收它们的内存（把暂时不用的内容挪到磁盘里）；

 

##### 7、非连续内存分配：分段

1）非连续内存分配的原因

​    -连续内存分配的缺点：分配给一个程序的物理内存是连续的；内存利用率低；有外碎片/内碎片问题；

​    -非连续内存分配的优点：分配给一个程序的物理内存是非连续的；更好的内存利用和管理；允许共享代码和数据(共享库等)；支持动态加载和动态链接；

​    -非连续内存分配的缺点：如何建立虚拟地址和物理地址之间的转换；软件方案(开销大)；硬件方案

2）两种硬件方案：分段和分页

3）分段：逻辑地址空间是连续的，物理地址是离散的；

4）分段寻址的方案：段访问机制，一个段指一个“内存块”，是一个逻辑地址空间。程序根据段访问机制访问内存地址需要一个二维的二元组(s段号，addr端内偏移)

5）段访问机制的硬件实现方案：段表

 

 

##### 8、非连续内存分配：分页

1）分页地址空间：划分物理内存至固定大小的帧，大小是2的幂，划分逻辑地址空间至相同大小的页；转换逻辑地址为物理地址（页表）

2）物理地址部分：页帧，物理内存被分割为大小相等的帧(物理地址部分)

​    -一个内存的物理地址是一个二元组(f,o)，f:帧号(它是F位的，因此意味着一共2F个帧)；o：帧内偏移(它是S位的，因此意味着每帧有2S字节)；物理地址=2^S x f + o。

3）逻辑地址部分：页，一个程序的逻辑地址空间被划分为大小相等的页（逻辑地址部分）

​    -（逻辑地址的）页内偏移量 = （物理地址的）帧内偏移量

​    -（逻辑地址的）页号大小可能不等于（物理地址的）帧号大小

4）页寻址机制的实现

​    页表实际上就是一个大的数组/hash表。它的index是 页号，对应的value是 页帧号，首先根据逻辑地址计算得到一个 页号，也就是index，再在页表中找到对应的 页帧号，最后根据 页帧号 计算得到物理地址；由于他们的页/帧内偏移相等，所以页表不需要保存这个数据。通过这种方式能够根据逻辑地址找到对应的物理地址。

除此之外，还有一些flags标志位，见下一节。

##### 9、非连续内存分配：页表****-****概述、****TLB

​    本节介绍如何优化页表的时间开销问题，解决办法是缓存。

​    TLB实际上是CPU的MMU内存管理单元保存的一段缓存，这段缓存保存的内容是 页表 的一部分，是经常访问到的那部分页表，其余不常用的页表内容保存在内存中。

TLB未命中，也叫TLB miss，这种情况比较少见，因为一页很大，32位系统一页是4K，如果采用局部性原理，那么访问4k次才会遇到一次TLB miss。

##### 10、非连续内存分配：页表****-****二级、多级页表

​    本节介绍如何优化页表的空间开销问题，解决方法是 多级页表。虽然增加了内存访问次数和开销，但是节省了保存页表的空间(时间换空间，然后在通过TLB来减少时间消耗)。

1）二级页表

逻辑地址中，页号部分分成了2部分，p1和p2。p1存放着二级页表的起始地址，p2的作用就是之前的p。p1找二级页表，p2找页，o找地址。这里体现了二级页表的另一个好处，就是p1对应的位置是flags，假如说resident bit是0，那么整个二级页表都不用在内存中保存，这个是一级页表无法实现的！

2）多级页表

例如64位操作系统采用5级页表

##### 11、非连续内存分配：反向页表****inverted page table

​    反向页表：页表来表示物理地址(页帧)号，而不是之前的逻辑地址(页号)，能够减少页表尺寸，但是给映射关系的建立带来点困难。

1）传统页表缺点：对于大地址空间，前向映射页表变得繁琐(例如64位系统采用5级页表)；逻辑地址空间增长速度快于物理地址空间，所以反向页表，也就是index是物理地址，value是逻辑地址，它的大小会小于传统页表。

2）反向页表的实现：基于页寄存器的方案

3）反向页表的实现：基于关联内存的方案

4）反向页表的实现：基于哈希查找hash的方案

##### 12、虚拟内存

1）起因：经常出现内存不够了。程序规模的增长大于存储器容量的增长。

​    把硬盘的空间也用上（扮演内存的作用），将不常用的放在硬盘上，常用的放在内存上。

2）内存不够用的情况下，怎么办？

​    如果程序太大，超过了内存的容量，可以采用手动的覆盖(overlay) 技术，只把需要的指令和数据保存在内存中

​    如果是程序太多，超过了内存的容量，可以采用自动的交换(swapping) 技术，把暂时不能执行的程序送到外存中

​    如果想在有限容量的内存中，以更小的页粒度为单位装入更多更大的程序，可以采用自动的虚拟存储技术 。

##### 13、覆盖技术

1）目标：在较小的可用内存中运行较大的程序。常用于多道程序系统，与分区存储管理配合使用。

2）原理：

​    把程序按照其自身逻辑结构，划分为若干个功能上相对独立的程序模块，那些不会同时执行的模块共享同一块内存区域，按时间先后来运行。

​    -必要部分(常用功能)的代码和数据常驻内存

​    -可选部分(不常用功能)在其它程序模块中实现，平时存放在外存中，在需要时才装入内存。

​    -不存在调用关系的模块不必同时装入内存，从而可以相互覆盖，即这些模块共用一个分区。

3）缺点：由程序员来把一个大的程序划分为若干个小的功能模块，并确定各个模块之间的覆盖关系，费时费力，增加了编程的复杂度。覆盖模块从外存装入内存，是以时间换空间。

 

##### 14、交换技术

1）目标：多道程序在内存中时，让正在运行的程序或需要运行的程序获得更多的内存资源。

2）方法：

​    -可将暂时不能运行的程序送到外存，从而获得空闲内存空间。
​    -操作系统把一个进程的整个地址空间的内容保存到外存中(换出swap out),而将将外存中的某个进程的地址空间读入到内存中(换入swap in)。换入换出内容大小为整个程序的地址空间。

3）交换技术实现的几个问题

​    -交换时机的确定：只有当内存空间不够或有不够的危险时换出；

-交换区的大小：必须足够大以存放所有用户进程的所有内存映像的拷贝，必须能对这些内存映像进行直接存取；

-程序换入时的重定位：因为换出换入后的内存位置不一定相同，所以最好采用动态地址映射的方法；

4）覆盖技术与交换技术的比较

​    覆盖只能发生在那些(程序内)相互之间没有调用关系的程序模块之间，因此程序员必须给出程序内的各个模块之间的逻辑覆盖结构。

​    交换技术是以在内存中的程序大小为单位来进行的，它不需要程序员给出各个模块之间的逻辑覆盖结构。

​    交换发生在内存中程序与管理程序或操作系统之间，而覆盖则发色会跟你在运行程序的内部。

##### 15、虚拟内存管理技术

1）目标：

​    解决覆盖技术给程序员负担大和交换技术处理器开销大的问题。

​    -像覆盖技术一样，不是把程序的所有内容都放在内存中，因而能够运行比当前的空闲内存空间还要大的程序。但做得更好，能由操作系统自动完成，无需程序员介入；

​    -能像交换技术那样，能够实现进程在内存和外存之间的交换，因而获得更多的空闲内存空间。但能做得更好，只对进程的部分内容在内存和外存之间进行交换。

2）程序的局部性原理

​    指程序在执行过程中的一个较短时间，所执行的指令地址和指令的操作数地址分别局限于一定区域，表现为：

​    时间局部性：一条指令的一次执行和下次执行，一个数据的一次访问和下次访问都集中在一个较短的时间里

​    空间局部性：当前指令和领近的几条指令，当前访问的数据和领近的几个数据都集中在一个较小区域内

​    程序的局部性原理表明，从理论上来说，虚拟存储技术是能够实现的，而且在实现了以后应该能够取得一个满意的效果的。

3）基本概念 

 4）基本特征

5）虚拟页式内存管理

6）后备存储

##### 16、最优页面置换算法

（1）功能目标

​    功能：当缺页中断发生，需要调入新的页面而内存已满时，选择内存当中哪个物理页面被置换。

​    目标：尽可能减少页面的换入换出次数(即缺页中断的次数)。把未来不再使用的或短期内较少使用的页面换出，通常只能在局部性原理的指导下依据过去的统计数据来进行预测。

​    页面锁定(frame locking)：用于描述必须常驻内存的操作系统的关键部分或时间关键(time-critical)的应用进程。实现方法是，在页表中添加锁定标志位(lock bit)。

（2）最优页面置换算法

​    基本思路：当一个缺页中断发生时，对于保存在内存中的每一个逻辑页面，计算在它的下一次访问之前，还需要等待多长时间，从中选择等待时间最长的那个，作为被置换的页面。

不过，这只是一种理想情况，在实际中无法实现，因为操作系统无法知道每一个页面要等待多长时间以后才会被再次访问。

​    可用作其它算法的性能评价的依据(在一个模拟器上运行某个程序，并记录每一次的页面访问情况，在第二遍运行时即可使用最优算法)。

##### 17、先进先出算法

##### 18、最近最久未使用算法（LRU）

##### 19、时钟页面置换算法

##### 20、二次机会法

​    如果是一次写操作，dirty bit会设置为1.说明内存访问这部分数据时是有写入操作的，和硬盘上原数据不一样，所以要写入硬盘，如果是0，对这部分内存没有写操作，那么说明内存和硬盘上内容是一样的，直接丢掉即可。

目的就是减少对硬盘的写操作。

​    如果used和dirty bit都是0，那么替换掉；如果其中一个是1，那么把这一位设置为0，指针往下走；如果都是1，那先把used换为0，说明有2次机会。

##### 21、最不常用算法（LFU）

##### 22、Belady现象，LRU、FIFO、Clock的比较

##### 23、两个全局置换算法

1）工作集页置换算法

2）缺页率页面置换算法

##### 24、抖动问题

## 四、进程和线程

##### 1、进程

1）进程定义：一个具有一定独立功能的程序在一个数据集合上的一次动态执行过程。

2）进程组成：

​    程序的代码

​       -程序处理的数据

​       -程序计数器的值，指示下一条将运行的指令

​       -一组通用的寄存器的当前值，堆，栈

​       -一组系统资源(如打开的文件)

​    总之，进程包含了正在运行的一个程序的所有状态信息。

b、进程与程序的联系

​    程序是产生进程的基础

​    -程序的每次运行构成不同的进程

​    -进程是程序功能的体现

​    -通过多次执行，一个程序可对应多个进程；通过调用关系，一个进程可包括多个程序。

c、进程与程序的区别

​    进程是动态的，程序是静态的：程序是有序代码的集合；进程是程序的执行，进程有核心态/用户态

​    -进程是暂时的，程序是永久的：进程是一个状态变化的过程，程序可长久保存

​    -进程与程序的组成不同：进程的组成包括程序，数据和进程控制块(进程的状态信息)

3）进程特点

动态性：可动态地创建，结束进程

并发性：进程可以被独立调度并占用处理机运行

独立性：不同进程的工作不互相影响

制约性：因访问共享数据/资源或进程间同步而产生制约

##### 2、进程间通信（IPC，InterProcess Communication）

1）信号

2）管道

3）消息队列

4）共享内存

## 五、系统调度

##### 1、面向通用计算系统的调度算法总结

​    实际上这些调度算法和实际的调度算法是有很多区别的(复杂的多)，但是基本的特征是类似的。

1）FCFS先来先服务

​    ->不公平，等待时间较长；

2）SPN/SRT短进程优先

​    ->不公平，但是平均等待时间最小；

​    ->需要精确预测计算机时间；

​    ->可能导致饥饿；

3）HRRN最高响应比优先

​    ->给予SPN调度的改进；

​    ->不可抢占；

4）Round Robin轮循

​    ->公平，但是平均等待时间较长；

5）MLFQ多级反馈队列

​    ->根据CPU和I/O状态动态调整；和SPN类似；

6）Fair-share scheduling公平共享调度

​    ->公平是第一要素。

 

## 六、死锁

##### 1、死锁成立的必要条件

1）互斥

2）持有并等待；

3）无抢占；

4）循环等待；

##### 2、死锁处理办法

1）死锁预防

2）死锁避免；（确保不会发生环形等待）

3）死锁检测；

4）死锁恢复；  